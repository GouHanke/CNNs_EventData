========================================================================================================
Experiment: exp029
Checkpoint path: experiments/exp029/checkpoint.pth

######################### Model architecture #########################
CNNLeNet(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (conv1): Conv2d(2, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): Linear(in_features=120, out_features=84, bias=False)
  (relu4): ReLU()
  (fc2): Linear(in_features=84, out_features=10, bias=False)
)
Total number of paramters in the model: 61620
Quantised model: True

################### Model successfully initialised ###################

################## Setting up training components ##################
Number of classes: 10
Model quantised: True
Device: (CPU)
12th Gen Intel(R) Core(TM) i5-12600KF
Number of epochs: 25
Criteria: CrossEntropyLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x00000198948C7700>
Patience: 7

################## Training components set up successfully ##################

############################## Data loading ##############################
Train set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_train_dataset.pth
Valid set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_valid_dataset.pth
Test set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_test_dataset.pth
Total number of samples in train_loader: 50000
Total number of samples in valid_loader: 10000
Total number of samples in test_loader: 10000

######################### Data loaded successfully #########################

################################## checkpoint info ##################################
No checkpoint found at experiments/exp029/checkpoint.pth. Starting training from scratch.

#####################################################################################

############################## Training started ##############################
Model saved at epoch 1 with validation loss 0.1467.
Epoch 1/25, Train Loss: 0.5771, Train Acc: 89.10%, Valid Loss: 0.1467, Valid Acc: 95.33%, Test Loss: 0.1396, Test Acc: 95.59%, Train Time: 21.69s
Model saved at epoch 2 with validation loss 0.0949.
Epoch 2/25, Train Loss: 0.1091, Train Acc: 96.50%, Valid Loss: 0.0949, Valid Acc: 96.86%, Test Loss: 0.0880, Test Acc: 97.17%, Train Time: 22.50s
Model saved at epoch 3 with validation loss 0.0890.
Epoch 3/25, Train Loss: 0.0801, Train Acc: 97.48%, Valid Loss: 0.0890, Valid Acc: 97.32%, Test Loss: 0.0897, Test Acc: 97.08%, Train Time: 21.88s
Model saved at epoch 4 with validation loss 0.0784.
Epoch 4/25, Train Loss: 0.0635, Train Acc: 97.96%, Valid Loss: 0.0784, Valid Acc: 97.47%, Test Loss: 0.0744, Test Acc: 97.56%, Train Time: 22.21s
Model saved at epoch 5 with validation loss 0.0686.
Epoch 5/25, Train Loss: 0.0519, Train Acc: 98.28%, Valid Loss: 0.0686, Valid Acc: 97.98%, Test Loss: 0.0708, Test Acc: 97.84%, Train Time: 21.58s
Epoch 6/25, Train Loss: 0.0417, Train Acc: 98.64%, Valid Loss: 0.0772, Valid Acc: 97.79%, Test Loss: 0.0812, Test Acc: 97.60%, Train Time: 22.19s
Model saved at epoch 7 with validation loss 0.0631.
Epoch 7/25, Train Loss: 0.0363, Train Acc: 98.85%, Valid Loss: 0.0631, Valid Acc: 98.05%, Test Loss: 0.0673, Test Acc: 98.06%, Train Time: 22.15s
Epoch 8/25, Train Loss: 0.0300, Train Acc: 99.00%, Valid Loss: 0.0805, Valid Acc: 97.81%, Test Loss: 0.0822, Test Acc: 97.69%, Train Time: 22.69s
Epoch 9/25, Train Loss: 0.0251, Train Acc: 99.13%, Valid Loss: 0.0800, Valid Acc: 97.71%, Test Loss: 0.0783, Test Acc: 97.76%, Train Time: 22.37s
Epoch 10/25, Train Loss: 0.0234, Train Acc: 99.25%, Valid Loss: 0.0828, Valid Acc: 97.82%, Test Loss: 0.0859, Test Acc: 97.63%, Train Time: 22.16s
Epoch 11/25, Train Loss: 0.0205, Train Acc: 99.36%, Valid Loss: 0.0778, Valid Acc: 97.85%, Test Loss: 0.0801, Test Acc: 97.91%, Train Time: 22.28s
Epoch 12/25, Train Loss: 0.0082, Train Acc: 99.77%, Valid Loss: 0.0667, Valid Acc: 98.27%, Test Loss: 0.0691, Test Acc: 98.26%, Train Time: 21.74s
Epoch 13/25, Train Loss: 0.0045, Train Acc: 99.90%, Valid Loss: 0.0706, Valid Acc: 98.34%, Test Loss: 0.0750, Test Acc: 98.30%, Train Time: 22.05s
Epoch 14/25, Train Loss: 0.0035, Train Acc: 99.92%, Valid Loss: 0.0764, Valid Acc: 98.24%, Test Loss: 0.0803, Test Acc: 98.31%, Train Time: 21.72s
Early stopping at epoch 14. No improvement in validation loss for 7 consecutive epochs.
Loaded the best model state based on validation loss.

        ############### Training completed in 309.21s. ###############
        Average time per epoch: 22.09s.
        Trained for 14/25 epochs.
        ##############################################################
        

############################## Training completed ##############################
========================================================================================================

!---------------------------- Quantised model saved to: experiments\exp029\quantised_model.pth ----------------------------!
scale=0.007874015718698502
zero_point=0
!-------------------------------------------------------------------------------------------------------------------------!

Model quantised:
CNNLeNet(
  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (conv1): QuantizedConv2d(2, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.07741253077983856, zero_point=78, bias=False)
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.21103356778621674, zero_point=95, bias=False)
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): QuantizedConv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), scale=0.15084217488765717, zero_point=83, bias=False)
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): QuantizedLinear(in_features=120, out_features=84, scale=0.1521466225385666, zero_point=56, qscheme=torch.per_channel_affine)
  (relu4): ReLU()
  (fc2): QuantizedLinear(in_features=84, out_features=10, scale=0.40951067209243774, zero_point=92, qscheme=torch.per_channel_affine)
)
========================================================================================================

######################################### Classification report #########################################
              precision    recall  f1-score   support

           0     0.9878    0.9878    0.9878       980
           1     0.9930    0.9930    0.9930      1135
           2     0.9893    0.9845    0.9869      1032
           3     0.9678    0.9832    0.9754      1010
           4     0.9908    0.9857    0.9883       982
           5     0.9710    0.9765    0.9737       892
           6     0.9802    0.9833    0.9818       958
           7     0.9902    0.9864    0.9883      1028
           8     0.9744    0.9754    0.9749       974
           9     0.9820    0.9713    0.9766      1009

    accuracy                         0.9829     10000
   macro avg     0.9826    0.9827    0.9827     10000
weighted avg     0.9829    0.9829    0.9829     10000


##########################################################################################################

############################################# Accuracy score #############################################
0.9829

##########################################################################################################
Model is on device: cpu

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 10000, Accuracy: 98.29%
Inference time for iteration 1: 0 min 7.21 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 10000, Accuracy: 98.29%
Inference time for iteration 2: 0 min 7.06 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 10000, Accuracy: 98.29%
Inference time for iteration 3: 0 min 7.37 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 10000, Accuracy: 98.29%
Inference time for iteration 4: 0 min 7.20 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 10000, Accuracy: 98.29%
Inference time for iteration 5: 0 min 7.34 sec

Average Inference time over 5 iterations: 0 min 7.24 sec

Average Inference time per sample: 0.72 ms

##################### [Inference time] - Testing completed #####################
