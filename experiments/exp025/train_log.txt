========================================================================================================
Experiment: exp025
Checkpoint path: experiments/exp025/checkpoint.pth

######################### Model architecture #########################
MobileNet(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (conv1): Sequential(
    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (conv2): DepthwiseSeparableConv(
    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv3): DepthwiseSeparableConv(
    (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv4): DepthwiseSeparableConv(
    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv5): DepthwiseSeparableConv(
    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv6): DepthwiseSeparableConv(
    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv7): DepthwiseSeparableConv(
    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv8): Sequential(
    (0): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (conv9): DepthwiseSeparableConv(
    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv10): DepthwiseSeparableConv(
    (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=1, bias=True)
)
Total number of paramters in the model: 3185889
Quantised model: True

################### Model successfully initialised ###################

################## Setting up training components ##################
Number of classes: 2
Model quantised: True
Device: (CPU)
12th Gen Intel(R) Core(TM) i5-12600KF
Number of epochs: 40
Criteria: BCEWithLogitsLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001B42C5ED150>
Patience: 7

################## Training components set up successfully ##################

############################## Data loading ##############################
Train set path: data/ncars/max_32x32_DATASETS/plain-binary/train_n_cars_dataset_maxpooling_1framepereventset_plain-binary.pth
Valid set path: data/ncars/max_32x32_DATASETS/plain-binary/valid_n_cars_dataset_maxpooling_1framepereventset_plain-binary.pth
Test set path: data/ncars/max_32x32_DATASETS/plain-binary/test_n_cars_dataset_maxpooling_1framepereventset_plain_binary.pth
Total number of samples in train_loader: 11566
Total number of samples in valid_loader: 3856
Total number of samples in test_loader: 8607

######################### Data loaded successfully #########################

################################## checkpoint info ##################################
No checkpoint found at experiments/exp025/checkpoint.pth. Starting training from scratch.

#####################################################################################

############################## Training started ##############################
Model saved at epoch 1 with validation loss 0.6929.
Epoch 1/40, Train Loss: 0.6929, Train Acc: 51.49%, Valid Loss: 0.6929, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 59.47s
Model saved at epoch 2 with validation loss 0.6928.
Epoch 2/40, Train Loss: 0.6929, Train Acc: 51.49%, Valid Loss: 0.6928, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 56.37s
Model saved at epoch 3 with validation loss 0.6927.
Epoch 3/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 79.91s
Model saved at epoch 4 with validation loss 0.6927.
Epoch 4/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 72.80s
Model saved at epoch 5 with validation loss 0.6927.
Epoch 5/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 58.81s
Epoch 6/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6931, Test Acc: 51.07%, Train Time: 123.95s
Epoch 7/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6928, Valid Acc: 51.48%, Test Loss: 0.6933, Test Acc: 51.07%, Train Time: 59.59s
Epoch 8/40, Train Loss: 0.6929, Train Acc: 51.49%, Valid Loss: 0.6930, Valid Acc: 51.48%, Test Loss: 0.6935, Test Acc: 51.07%, Train Time: 60.72s
Epoch 9/40, Train Loss: 0.6931, Train Acc: 51.49%, Valid Loss: 0.6930, Valid Acc: 51.48%, Test Loss: 0.6935, Test Acc: 51.07%, Train Time: 60.20s
Epoch 10/40, Train Loss: 0.6929, Train Acc: 51.49%, Valid Loss: 0.6929, Valid Acc: 51.48%, Test Loss: 0.6933, Test Acc: 51.07%, Train Time: 60.21s
Epoch 11/40, Train Loss: 0.6929, Train Acc: 51.49%, Valid Loss: 0.6928, Valid Acc: 51.48%, Test Loss: 0.6932, Test Acc: 51.07%, Train Time: 60.97s
Epoch 12/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6928, Valid Acc: 51.48%, Test Loss: 0.6932, Test Acc: 51.07%, Train Time: 59.67s
Early stopping at epoch 12. No improvement in validation loss for 7 consecutive epochs.
Loaded the best model state based on validation loss.

        ############### Training completed in 812.66s. ###############
        Average time per epoch: 67.72s.
        Trained for 12/40 epochs.
        ##############################################################
        

############################## Training completed ##############################
========================================================================================================

!---------------------------- Quantised model saved to: experiments\exp025\quantised_model.pth ----------------------------!
scale=0.007874015718698502
zero_point=0
!-------------------------------------------------------------------------------------------------------------------------!

Model quantised:
MobileNet(
  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (conv1): Sequential(
    (0): QuantizedConv2d(2, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.023567380383610725, zero_point=67, padding=(1, 1), bias=False)
    (1): QuantizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (conv2): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.0480734258890152, zero_point=67, padding=(1, 1), groups=32, bias=False)
    (pointwise): QuantizedConv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.019899310544133186, zero_point=60, bias=False)
  )
  (conv3): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), scale=0.012982687912881374, zero_point=78, padding=(1, 1), groups=64, bias=False)
    (pointwise): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.0066448082216084, zero_point=65, bias=False)
  )
  (conv4): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.004366048611700535, zero_point=77, padding=(1, 1), groups=128, bias=False)
    (pointwise): QuantizedConv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.0020804672967642546, zero_point=60, bias=False)
  )
  (conv5): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.0011689256643876433, zero_point=71, padding=(1, 1), groups=128, bias=False)
    (pointwise): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.0005902256234548986, zero_point=63, bias=False)
  )
  (conv6): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00033398476080037653, zero_point=68, padding=(1, 1), groups=256, bias=False)
    (pointwise): QuantizedConv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.00016973655147012323, zero_point=65, bias=False)
  )
  (conv7): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=8.496783266309649e-05, zero_point=63, padding=(1, 1), groups=256, bias=False)
    (pointwise): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), scale=4.677541073760949e-05, zero_point=61, bias=False)
  )
  (conv8): Sequential(
    (0): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.8794407878885977e-05, zero_point=65, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=9.051489541889168e-06, zero_point=63, bias=False)
    )
    (1): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=4.241557235218352e-06, zero_point=62, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=2.089714143949095e-06, zero_point=63, bias=False)
    )
    (2): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0494482012290973e-06, zero_point=62, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=6.247447004170681e-07, zero_point=63, bias=False)
    )
    (3): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.2010839611775737e-07, zero_point=65, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, bias=False)
    )
    (4): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, bias=False)
    )
  )
  (conv9): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=1.1920928955078125e-07, zero_point=0, padding=(1, 1), groups=512, bias=False)
    (pointwise): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, bias=False)
  )
  (conv10): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, padding=(1, 1), groups=1024, bias=False)
    (pointwise): QuantizedConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, bias=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): QuantizedLinear(in_features=1024, out_features=1, scale=0.000696996517945081, zero_point=0, qscheme=torch.per_channel_affine)
)
========================================================================================================

######################################### Classification report #########################################
              precision    recall  f1-score   support

         0.0     0.0000    0.0000    0.0000      4211
         1.0     0.5107    1.0000    0.6762      4396

    accuracy                         0.5107      8607
   macro avg     0.2554    0.5000    0.3381      8607
weighted avg     0.2609    0.5107    0.3453      8607


##########################################################################################################

############################################# Accuracy score #############################################
0.51074706634135

##########################################################################################################
Model is on device: cpu

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 1: 0 min 24.05 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 2: 0 min 24.85 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 3: 0 min 25.04 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 4: 0 min 24.34 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 5: 0 min 23.87 sec

Average Inference time over 5 iterations: 0 min 24.43 sec

Average Inference time per sample: 2.84 ms

##################### [Inference time] - Testing completed #####################
