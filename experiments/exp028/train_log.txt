========================================================================================================
Experiment: exp028
Checkpoint path: experiments/exp028/checkpoint.pth

######################### Model architecture #########################
CNNLeNet(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (conv1): Conv2d(2, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): Linear(in_features=120, out_features=84, bias=False)
  (relu4): ReLU()
  (fc2): Linear(in_features=84, out_features=10, bias=False)
)
Total number of paramters in the model: 61620
Quantised model: True

################### Model successfully initialised ###################

################## Setting up training components ##################
Number of classes: 10
Model quantised: True
Device: (CPU)
12th Gen Intel(R) Core(TM) i5-12600KF
Number of epochs: 25
Criteria: CrossEntropyLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001A1D43A3700>
Patience: 7

################## Training components set up successfully ##################

############################## Data loading ##############################
Train set path: data/nmnist/Plain/Plain_1FramePerEventSet_train_dataset.pth
Valid set path: data/nmnist/Plain/Plain_1FramePerEventSet_valid_dataset.pth
Test set path: data/nmnist/Plain/Plain_1FramePerEventSet_test_dataset.pth
Total number of samples in train_loader: 10000
Total number of samples in valid_loader: 10000
Total number of samples in test_loader: 10000

######################### Data loaded successfully #########################

################################## checkpoint info ##################################
No checkpoint found at experiments/exp028/checkpoint.pth. Starting training from scratch.

#####################################################################################

############################## Training started ##############################
Model saved at epoch 1 with validation loss 0.3189.
Epoch 1/25, Train Loss: 1.4327, Train Acc: 83.94%, Valid Loss: 0.3189, Valid Acc: 90.06%, Test Loss: 0.3157, Test Acc: 92.15%, Train Time: 4.76s
Model saved at epoch 2 with validation loss 0.2250.
Epoch 2/25, Train Loss: 0.2039, Train Acc: 93.59%, Valid Loss: 0.2250, Valid Acc: 93.38%, Test Loss: 0.1740, Test Acc: 95.47%, Train Time: 4.50s
Model saved at epoch 3 with validation loss 0.2160.
Epoch 3/25, Train Loss: 0.1492, Train Acc: 94.94%, Valid Loss: 0.2160, Valid Acc: 93.35%, Test Loss: 0.1605, Test Acc: 95.49%, Train Time: 4.65s
Model saved at epoch 4 with validation loss 0.1879.
Epoch 4/25, Train Loss: 0.1186, Train Acc: 96.14%, Valid Loss: 0.1879, Valid Acc: 94.40%, Test Loss: 0.0999, Test Acc: 97.08%, Train Time: 4.71s
Model saved at epoch 5 with validation loss 0.1570.
Epoch 5/25, Train Loss: 0.0942, Train Acc: 96.85%, Valid Loss: 0.1570, Valid Acc: 95.41%, Test Loss: 0.0739, Test Acc: 97.93%, Train Time: 4.63s
Epoch 6/25, Train Loss: 0.0772, Train Acc: 97.36%, Valid Loss: 0.2297, Valid Acc: 93.31%, Test Loss: 0.1439, Test Acc: 95.88%, Train Time: 4.74s
Epoch 7/25, Train Loss: 0.0612, Train Acc: 97.88%, Valid Loss: 0.1737, Valid Acc: 95.10%, Test Loss: 0.0600, Test Acc: 98.22%, Train Time: 4.65s
Epoch 8/25, Train Loss: 0.0513, Train Acc: 98.21%, Valid Loss: 0.1789, Valid Acc: 95.20%, Test Loss: 0.0877, Test Acc: 97.66%, Train Time: 4.80s
Epoch 9/25, Train Loss: 0.0403, Train Acc: 98.60%, Valid Loss: 0.1920, Valid Acc: 94.87%, Test Loss: 0.0928, Test Acc: 97.55%, Train Time: 4.63s
Model saved at epoch 10 with validation loss 0.1568.
Epoch 10/25, Train Loss: 0.0228, Train Acc: 99.33%, Valid Loss: 0.1568, Valid Acc: 96.01%, Test Loss: 0.0400, Test Acc: 98.93%, Train Time: 4.68s
Epoch 11/25, Train Loss: 0.0133, Train Acc: 99.67%, Valid Loss: 0.1628, Valid Acc: 96.06%, Test Loss: 0.0391, Test Acc: 98.91%, Train Time: 4.69s
Epoch 12/25, Train Loss: 0.0103, Train Acc: 99.69%, Valid Loss: 0.1684, Valid Acc: 96.15%, Test Loss: 0.0392, Test Acc: 98.95%, Train Time: 4.75s
Epoch 13/25, Train Loss: 0.0086, Train Acc: 99.77%, Valid Loss: 0.1745, Valid Acc: 96.15%, Test Loss: 0.0389, Test Acc: 98.95%, Train Time: 4.61s
Epoch 14/25, Train Loss: 0.0070, Train Acc: 99.87%, Valid Loss: 0.1805, Valid Acc: 96.05%, Test Loss: 0.0395, Test Acc: 98.95%, Train Time: 4.50s
Epoch 15/25, Train Loss: 0.0056, Train Acc: 99.90%, Valid Loss: 0.1816, Valid Acc: 96.10%, Test Loss: 0.0377, Test Acc: 99.04%, Train Time: 4.65s
Epoch 16/25, Train Loss: 0.0055, Train Acc: 99.91%, Valid Loss: 0.1827, Valid Acc: 96.14%, Test Loss: 0.0372, Test Acc: 99.07%, Train Time: 4.54s
Epoch 17/25, Train Loss: 0.0052, Train Acc: 99.91%, Valid Loss: 0.1836, Valid Acc: 96.10%, Test Loss: 0.0368, Test Acc: 99.05%, Train Time: 4.55s
Early stopping at epoch 17. No improvement in validation loss for 7 consecutive epochs.
Loaded the best model state based on validation loss.

        ############### Training completed in 79.04s. ###############
        Average time per epoch: 4.65s.
        Trained for 17/25 epochs.
        ##############################################################
        

############################## Training completed ##############################
========================================================================================================

!---------------------------- Quantised model saved to: experiments\exp028\quantised_model.pth ----------------------------!
scale=0.10375804454088211
zero_point=10
!-------------------------------------------------------------------------------------------------------------------------!

Model quantised:
CNNLeNet(
  (quant): Quantize(scale=tensor([0.1038]), zero_point=tensor([10]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (conv1): QuantizedConv2d(2, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.3349035382270813, zero_point=71, bias=False)
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.4205630421638489, zero_point=78, bias=False)
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): QuantizedConv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), scale=0.352456271648407, zero_point=76, bias=False)
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): QuantizedLinear(in_features=120, out_features=84, scale=0.27219054102897644, zero_point=50, qscheme=torch.per_channel_affine)
  (relu4): ReLU()
  (fc2): QuantizedLinear(in_features=84, out_features=10, scale=0.4884462058544159, zero_point=80, qscheme=torch.per_channel_affine)
)
========================================================================================================

######################################### Classification report #########################################
              precision    recall  f1-score   support

           0     0.9889    0.9980    0.9934       980
           1     0.9861    1.0000    0.9930      1135
           2     0.9942    0.9893    0.9917      1032
           3     0.9921    0.9950    0.9936      1010
           4     0.9809    0.9949    0.9879       982
           5     0.9933    0.9922    0.9927       892
           6     0.9916    0.9916    0.9916       958
           7     0.9902    0.9874    0.9888      1028
           8     0.9979    0.9784    0.9881       974
           9     0.9899    0.9762    0.9830      1009

    accuracy                         0.9904     10000
   macro avg     0.9905    0.9903    0.9904     10000
weighted avg     0.9904    0.9904    0.9904     10000


##########################################################################################################

############################################# Accuracy score #############################################
0.9904

##########################################################################################################
Model is on device: cpu

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 10000, Accuracy: 99.04%
Inference time for iteration 1: 0 min 7.15 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 10000, Accuracy: 99.04%
Inference time for iteration 2: 0 min 7.24 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 10000, Accuracy: 99.04%
Inference time for iteration 3: 0 min 7.12 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 10000, Accuracy: 99.04%
Inference time for iteration 4: 0 min 7.22 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 10000, Accuracy: 99.04%
Inference time for iteration 5: 0 min 7.11 sec

Average Inference time over 5 iterations: 0 min 7.17 sec

Average Inference time per sample: 0.72 ms

##################### [Inference time] - Testing completed #####################
