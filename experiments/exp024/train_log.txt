========================================================================================================
Experiment: exp024
Checkpoint path: experiments/exp024/checkpoint.pth

######################### Model architecture #########################
MobileNet(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (conv1): Sequential(
    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (conv2): DepthwiseSeparableConv(
    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv3): DepthwiseSeparableConv(
    (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv4): DepthwiseSeparableConv(
    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv5): DepthwiseSeparableConv(
    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv6): DepthwiseSeparableConv(
    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv7): DepthwiseSeparableConv(
    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv8): Sequential(
    (0): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (conv9): DepthwiseSeparableConv(
    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv10): DepthwiseSeparableConv(
    (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=1, bias=True)
)
Total number of paramters in the model: 3185889
Quantised model: True

################### Model successfully initialised ###################

################## Setting up training components ##################
Number of classes: 2
Model quantised: True
Device: (CPU)
12th Gen Intel(R) Core(TM) i5-12600KF
Number of epochs: 40
Criteria: BCEWithLogitsLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000001B24A629150>
Patience: 7

################## Training components set up successfully ##################

############################## Data loading ##############################
Train set path: data/ncars/max_32x32_DATASETS/plain/train_n_cars_dataset_maxpooling_1framepereventset_plain.pth
Valid set path: data/ncars/max_32x32_DATASETS/plain/valid_n_cars_dataset_maxpooling_1framepereventset_plain.pth
Test set path: data/ncars/max_32x32_DATASETS/plain/test_n_cars_dataset_maxpooling_1framepereventset_plain.pth
Total number of samples in train_loader: 11566
Total number of samples in valid_loader: 3856
Total number of samples in test_loader: 8607

######################### Data loaded successfully #########################

################################## checkpoint info ##################################
No checkpoint found at experiments/exp024/checkpoint.pth. Starting training from scratch.

#####################################################################################

############################## Training started ##############################
Model saved at epoch 1 with validation loss 0.6929.
Epoch 1/40, Train Loss: 0.6929, Train Acc: 51.49%, Valid Loss: 0.6929, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 58.84s
Model saved at epoch 2 with validation loss 0.6928.
Epoch 2/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6928, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 60.26s
Model saved at epoch 3 with validation loss 0.6927.
Epoch 3/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 58.71s
Model saved at epoch 4 with validation loss 0.6927.
Epoch 4/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6928, Test Acc: 51.07%, Train Time: 141.72s
Model saved at epoch 5 with validation loss 0.6927.
Epoch 5/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 103.72s
Model saved at epoch 6 with validation loss 0.6927.
Epoch 6/40, Train Loss: 0.6928, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 151.02s
Epoch 7/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 58.69s
Epoch 8/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 58.39s
Model saved at epoch 9 with validation loss 0.6927.
Epoch 9/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 59.27s
Epoch 10/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6929, Test Acc: 51.07%, Train Time: 400.02s
Epoch 11/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 58.73s
Epoch 12/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 61.78s
Epoch 13/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 60.41s
Epoch 14/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 62.09s
Epoch 15/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 62.37s
Epoch 16/40, Train Loss: 0.6927, Train Acc: 51.49%, Valid Loss: 0.6927, Valid Acc: 51.48%, Test Loss: 0.6930, Test Acc: 51.07%, Train Time: 60.66s
Early stopping at epoch 16. No improvement in validation loss for 7 consecutive epochs.
Loaded the best model state based on validation loss.

        ############### Training completed in 1516.68s. ###############
        Average time per epoch: 94.79s.
        Trained for 16/40 epochs.
        ##############################################################
        

############################## Training completed ##############################
========================================================================================================

!---------------------------- Quantised model saved to: experiments\exp024\quantised_model.pth ----------------------------!
scale=0.14168250560760498
zero_point=7
!-------------------------------------------------------------------------------------------------------------------------!

Model quantised:
MobileNet(
  (quant): Quantize(scale=tensor([0.1417]), zero_point=tensor([7]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (conv1): Sequential(
    (0): QuantizedConv2d(2, 32, kernel_size=(3, 3), stride=(2, 2), scale=0.13214537501335144, zero_point=67, padding=(1, 1), bias=False)
    (1): QuantizedBatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (conv2): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.07524103671312332, zero_point=61, padding=(1, 1), groups=32, bias=False)
    (pointwise): QuantizedConv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.03622861206531525, zero_point=66, bias=False)
  )
  (conv3): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), scale=0.017451468855142593, zero_point=65, padding=(1, 1), groups=64, bias=False)
    (pointwise): QuantizedConv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.00939098745584488, zero_point=65, bias=False)
  )
  (conv4): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=0.004786224570125341, zero_point=65, padding=(1, 1), groups=128, bias=False)
    (pointwise): QuantizedConv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.0024407284799963236, zero_point=62, bias=False)
  )
  (conv5): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), scale=0.0012061863671988249, zero_point=64, padding=(1, 1), groups=128, bias=False)
    (pointwise): QuantizedConv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.0006701035308651626, zero_point=63, bias=False)
  )
  (conv6): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.00034774895175360143, zero_point=61, padding=(1, 1), groups=256, bias=False)
    (pointwise): QuantizedConv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.00017199231660924852, zero_point=64, bias=False)
  )
  (conv7): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), scale=8.70319563546218e-05, zero_point=65, padding=(1, 1), groups=256, bias=False)
    (pointwise): QuantizedConv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), scale=4.9296471843263134e-05, zero_point=63, bias=False)
  )
  (conv8): Sequential(
    (0): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=2.013298581005074e-05, zero_point=63, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=9.528758710075635e-06, zero_point=64, bias=False)
    )
    (1): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=4.4440189412853215e-06, zero_point=63, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=2.176367388528888e-06, zero_point=64, bias=False)
    )
    (2): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.085018766389112e-06, zero_point=63, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=6.24415577021864e-07, zero_point=65, bias=False)
    )
    (3): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.2925964654186828e-07, zero_point=56, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=1, bias=False)
    )
    (4): DepthwiseSeparableConv(
      (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, padding=(1, 1), groups=512, bias=False)
      (pointwise): QuantizedConv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, bias=False)
    )
  )
  (conv9): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), scale=1.1920928955078125e-07, zero_point=0, padding=(1, 1), groups=512, bias=False)
    (pointwise): QuantizedConv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, bias=False)
  )
  (conv10): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, padding=(1, 1), groups=1024, bias=False)
    (pointwise): QuantizedConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), scale=1.1920928955078125e-07, zero_point=0, bias=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): QuantizedLinear(in_features=1024, out_features=1, scale=0.0005263729835860431, zero_point=0, qscheme=torch.per_channel_affine)
)
========================================================================================================

######################################### Classification report #########################################
              precision    recall  f1-score   support

         0.0     0.0000    0.0000    0.0000      4211
         1.0     0.5107    1.0000    0.6762      4396

    accuracy                         0.5107      8607
   macro avg     0.2554    0.5000    0.3381      8607
weighted avg     0.2609    0.5107    0.3453      8607


##########################################################################################################

############################################# Accuracy score #############################################
0.51074706634135

##########################################################################################################
Model is on device: cpu

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 1: 0 min 27.38 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 2: 0 min 26.97 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 3: 0 min 26.01 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 4: 0 min 26.73 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 8607, Accuracy: 51.07%
Inference time for iteration 5: 0 min 25.90 sec

Average Inference time over 5 iterations: 0 min 26.60 sec

Average Inference time per sample: 3.09 ms

##################### [Inference time] - Testing completed #####################
