========================================================================================================
Experiment: exp037
Checkpoint path: experiments/exp037/checkpoint.pth

######################### Model architecture #########################
SeparableConv_LeNet(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (conv1): DepthwiseSeparableConv(
    (depthwise): Conv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), groups=2, bias=False)
    (pointwise): Conv2d(2, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): DepthwiseSeparableConv(
    (depthwise): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1), groups=6, bias=False)
    (pointwise): Conv2d(6, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): DepthwiseSeparableConv(
    (depthwise): Conv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), groups=16, bias=False)
    (pointwise): Conv2d(16, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): Linear(in_features=120, out_features=84, bias=False)
  (relu4): ReLU()
  (fc2): Linear(in_features=84, out_features=10, bias=False)
)
Total number of paramters in the model: 13548
Quantised model: True

################### Model successfully initialised ###################

################## Setting up training components ##################
Number of classes: 10
Model quantised: True
Device: (CPU)
12th Gen Intel(R) Core(TM) i5-12600KF
Number of epochs: 25
Criteria: CrossEntropyLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x000002C5B1E0CBE0>
Patience: 7

################## Training components set up successfully ##################

############################## Data loading ##############################
Train set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_train_dataset.pth
Valid set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_valid_dataset.pth
Test set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_test_dataset.pth
Total number of samples in train_loader: 50000
Total number of samples in valid_loader: 10000
Total number of samples in test_loader: 10000

######################### Data loaded successfully #########################

################################## checkpoint info ##################################
No checkpoint found at experiments/exp037/checkpoint.pth. Starting training from scratch.

#####################################################################################

############################## Training started ##############################
Model saved at epoch 1 with validation loss 0.2984.
Epoch 1/25, Train Loss: 0.9507, Train Acc: 81.34%, Valid Loss: 0.2984, Valid Acc: 90.58%, Test Loss: 0.2828, Test Acc: 90.96%, Train Time: 30.61s
Model saved at epoch 2 with validation loss 0.2450.
Epoch 2/25, Train Loss: 0.2690, Train Acc: 91.23%, Valid Loss: 0.2450, Valid Acc: 92.32%, Test Loss: 0.2328, Test Acc: 92.53%, Train Time: 30.63s
Model saved at epoch 3 with validation loss 0.2068.
Epoch 3/25, Train Loss: 0.2177, Train Acc: 92.82%, Valid Loss: 0.2068, Valid Acc: 93.55%, Test Loss: 0.1915, Test Acc: 93.74%, Train Time: 30.66s
Model saved at epoch 4 with validation loss 0.1906.
Epoch 4/25, Train Loss: 0.1901, Train Acc: 93.92%, Valid Loss: 0.1906, Valid Acc: 94.00%, Test Loss: 0.1767, Test Acc: 94.12%, Train Time: 31.47s
Model saved at epoch 5 with validation loss 0.1761.
Epoch 5/25, Train Loss: 0.1709, Train Acc: 94.47%, Valid Loss: 0.1761, Valid Acc: 94.32%, Test Loss: 0.1699, Test Acc: 94.59%, Train Time: 30.70s
Model saved at epoch 6 with validation loss 0.1658.
Epoch 6/25, Train Loss: 0.1575, Train Acc: 94.95%, Valid Loss: 0.1658, Valid Acc: 94.74%, Test Loss: 0.1637, Test Acc: 94.58%, Train Time: 31.18s
Model saved at epoch 7 with validation loss 0.1583.
Epoch 7/25, Train Loss: 0.1468, Train Acc: 95.22%, Valid Loss: 0.1583, Valid Acc: 94.78%, Test Loss: 0.1484, Test Acc: 95.24%, Train Time: 30.38s
Epoch 8/25, Train Loss: 0.1391, Train Acc: 95.50%, Valid Loss: 0.1671, Valid Acc: 94.56%, Test Loss: 0.1619, Test Acc: 94.77%, Train Time: 30.19s
Model saved at epoch 9 with validation loss 0.1474.
Epoch 9/25, Train Loss: 0.1324, Train Acc: 95.67%, Valid Loss: 0.1474, Valid Acc: 95.29%, Test Loss: 0.1510, Test Acc: 95.06%, Train Time: 30.67s
Model saved at epoch 10 with validation loss 0.1456.
Epoch 10/25, Train Loss: 0.1271, Train Acc: 95.92%, Valid Loss: 0.1456, Valid Acc: 95.37%, Test Loss: 0.1461, Test Acc: 95.32%, Train Time: 30.50s
Model saved at epoch 11 with validation loss 0.1427.
Epoch 11/25, Train Loss: 0.1215, Train Acc: 96.03%, Valid Loss: 0.1427, Valid Acc: 95.39%, Test Loss: 0.1394, Test Acc: 95.43%, Train Time: 30.77s
Model saved at epoch 12 with validation loss 0.1363.
Epoch 12/25, Train Loss: 0.1167, Train Acc: 96.18%, Valid Loss: 0.1363, Valid Acc: 95.52%, Test Loss: 0.1386, Test Acc: 95.41%, Train Time: 30.09s
Epoch 13/25, Train Loss: 0.1117, Train Acc: 96.29%, Valid Loss: 0.1447, Valid Acc: 95.28%, Test Loss: 0.1456, Test Acc: 95.45%, Train Time: 31.64s
Model saved at epoch 14 with validation loss 0.1355.
Epoch 14/25, Train Loss: 0.1083, Train Acc: 96.45%, Valid Loss: 0.1355, Valid Acc: 95.65%, Test Loss: 0.1344, Test Acc: 95.68%, Train Time: 31.90s
Epoch 15/25, Train Loss: 0.1044, Train Acc: 96.56%, Valid Loss: 0.1398, Valid Acc: 95.64%, Test Loss: 0.1387, Test Acc: 95.57%, Train Time: 31.55s
Model saved at epoch 16 with validation loss 0.1304.
Epoch 16/25, Train Loss: 0.1004, Train Acc: 96.63%, Valid Loss: 0.1304, Valid Acc: 95.92%, Test Loss: 0.1313, Test Acc: 95.90%, Train Time: 31.33s
Epoch 17/25, Train Loss: 0.0964, Train Acc: 96.80%, Valid Loss: 0.1395, Valid Acc: 95.61%, Test Loss: 0.1381, Test Acc: 95.56%, Train Time: 32.14s
Epoch 18/25, Train Loss: 0.0944, Train Acc: 96.85%, Valid Loss: 0.1401, Valid Acc: 95.54%, Test Loss: 0.1374, Test Acc: 95.67%, Train Time: 31.81s
Epoch 19/25, Train Loss: 0.0908, Train Acc: 96.95%, Valid Loss: 0.1379, Valid Acc: 95.70%, Test Loss: 0.1350, Test Acc: 95.82%, Train Time: 31.55s
Model saved at epoch 20 with validation loss 0.1298.
Epoch 20/25, Train Loss: 0.0897, Train Acc: 96.94%, Valid Loss: 0.1298, Valid Acc: 96.12%, Test Loss: 0.1319, Test Acc: 95.83%, Train Time: 31.65s
Epoch 21/25, Train Loss: 0.0866, Train Acc: 97.07%, Valid Loss: 0.1345, Valid Acc: 95.95%, Test Loss: 0.1354, Test Acc: 95.72%, Train Time: 192.00s
Epoch 22/25, Train Loss: 0.0830, Train Acc: 97.16%, Valid Loss: 0.1349, Valid Acc: 95.92%, Test Loss: 0.1369, Test Acc: 95.83%, Train Time: 40.75s
Epoch 23/25, Train Loss: 0.0813, Train Acc: 97.23%, Valid Loss: 0.1445, Valid Acc: 95.68%, Test Loss: 0.1467, Test Acc: 95.68%, Train Time: 28.64s
Epoch 24/25, Train Loss: 0.0796, Train Acc: 97.32%, Valid Loss: 0.1545, Valid Acc: 95.62%, Test Loss: 0.1540, Test Acc: 95.58%, Train Time: 29.74s
Epoch 25/25, Train Loss: 0.0574, Train Acc: 98.08%, Valid Loss: 0.1318, Valid Acc: 96.27%, Test Loss: 0.1323, Test Acc: 96.09%, Train Time: 28.60s
Loaded the best model state based on validation loss.

        ############### Training completed in 941.13s. ###############
        Average time per epoch: 37.65s.
        Trained for 25/25 epochs.
        ##############################################################
        

############################## Training completed ##############################
========================================================================================================

!---------------------------- Quantised model saved to: experiments\exp037\quantised_model.pth ----------------------------!
scale=0.007874015718698502
zero_point=0
!-------------------------------------------------------------------------------------------------------------------------!

Model quantised:
SeparableConv_LeNet(
  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (conv1): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(2, 2, kernel_size=(5, 5), stride=(1, 1), scale=0.04487869516015053, zero_point=94, groups=2, bias=False)
    (pointwise): QuantizedConv2d(2, 6, kernel_size=(1, 1), stride=(1, 1), scale=0.09044580161571503, zero_point=72, bias=False)
  )
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(6, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.09166637808084488, zero_point=52, groups=6, bias=False)
    (pointwise): QuantizedConv2d(6, 16, kernel_size=(1, 1), stride=(1, 1), scale=0.11557497829198837, zero_point=69, bias=False)
  )
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): DepthwiseSeparableConv(
    (depthwise): QuantizedConv2d(16, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.05805923417210579, zero_point=68, groups=16, bias=False)
    (pointwise): QuantizedConv2d(16, 120, kernel_size=(1, 1), stride=(1, 1), scale=0.08711759001016617, zero_point=72, bias=False)
  )
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): QuantizedLinear(in_features=120, out_features=84, scale=0.20689702033996582, zero_point=80, qscheme=torch.per_channel_affine)
  (relu4): ReLU()
  (fc2): QuantizedLinear(in_features=84, out_features=10, scale=0.3337631821632385, zero_point=95, qscheme=torch.per_channel_affine)
)
========================================================================================================

######################################### Classification report #########################################
              precision    recall  f1-score   support

           0     0.9754    0.9694    0.9724       980
           1     0.9860    0.9894    0.9877      1135
           2     0.9564    0.9767    0.9664      1032
           3     0.9403    0.9505    0.9453      1010
           4     0.9695    0.9715    0.9705       982
           5     0.9487    0.9339    0.9412       892
           6     0.9615    0.9645    0.9630       958
           7     0.9754    0.9650    0.9702      1028
           8     0.9360    0.9302    0.9331       974
           9     0.9522    0.9475    0.9498      1009

    accuracy                         0.9606     10000
   macro avg     0.9601    0.9599    0.9600     10000
weighted avg     0.9606    0.9606    0.9606     10000


##########################################################################################################

############################################# Accuracy score #############################################
0.9606

##########################################################################################################
Model is on device: cpu

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 10000, Accuracy: 96.06%
Inference time for iteration 1: 0 min 12.87 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 10000, Accuracy: 96.06%
Inference time for iteration 2: 0 min 12.41 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 10000, Accuracy: 96.06%
Inference time for iteration 3: 0 min 13.13 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 10000, Accuracy: 96.06%
Inference time for iteration 4: 0 min 12.59 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 10000, Accuracy: 96.06%
Inference time for iteration 5: 0 min 12.93 sec

Average Inference time over 5 iterations: 0 min 12.79 sec

Average Inference time per sample: 1.28 ms

##################### [Inference time] - Testing completed #####################
