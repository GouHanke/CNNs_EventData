========================================================================================================
Experiment: exp017
Checkpoint path: experiments/exp017/checkpoint.pth

######################### Model architecture #########################
CNNLeNet(
  (quant): QuantStub()
  (dequant): DeQuantStub()
  (conv1): Conv2d(2, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), bias=False)
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): Linear(in_features=120, out_features=84, bias=False)
  (relu4): ReLU()
  (fc2): Linear(in_features=84, out_features=10, bias=False)
)
Total number of paramters in the model: 61620
Quantised model: True

################### Model successfully initialised ###################

################## Setting up training components ##################
Number of classes: 10
Model quantised: True
Device: (CPU)
Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz
Number of epochs: 25
Criteria: CrossEntropyLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x0000021EB92A47F0>
Patience: 7

################## Training components set up successfully ##################

############################## Data loading ##############################
Train set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_train_dataset.pth
Valid set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_valid_dataset.pth
Test set path: data/nmnist/Plain_Binary/Plain-Binary_1FramePerEventSet_test_dataset.pth
Total number of samples in train_loader: 50000
Total number of samples in valid_loader: 10000
Total number of samples in test_loader: 10000

######################### Data loaded successfully #########################

################################## checkpoint info ##################################
No checkpoint found at experiments/exp017/checkpoint.pth. Starting training from scratch.

#####################################################################################

############################## Training started ##############################
Model saved at epoch 1 with validation loss 0.1351.
Epoch 1/25, Train Loss: 0.3275, Train Acc: 89.47%, Valid Loss: 0.1351, Valid Acc: 95.61%, Test Loss: 0.1281, Test Acc: 95.98%, Train Time: 17.11s
Model saved at epoch 2 with validation loss 0.0840.
Epoch 2/25, Train Loss: 0.1087, Train Acc: 96.63%, Valid Loss: 0.0840, Valid Acc: 97.27%, Test Loss: 0.0790, Test Acc: 97.38%, Train Time: 18.37s
Model saved at epoch 3 with validation loss 0.0691.
Epoch 3/25, Train Loss: 0.0796, Train Acc: 97.45%, Valid Loss: 0.0691, Valid Acc: 97.84%, Test Loss: 0.0626, Test Acc: 98.00%, Train Time: 16.34s
Epoch 4/25, Train Loss: 0.0607, Train Acc: 98.02%, Valid Loss: 0.0761, Valid Acc: 97.68%, Test Loss: 0.0687, Test Acc: 97.72%, Train Time: 16.51s
Model saved at epoch 5 with validation loss 0.0635.
Epoch 5/25, Train Loss: 0.0478, Train Acc: 98.44%, Valid Loss: 0.0635, Valid Acc: 98.17%, Test Loss: 0.0638, Test Acc: 98.04%, Train Time: 15.58s
Model saved at epoch 6 with validation loss 0.0584.
Epoch 6/25, Train Loss: 0.0404, Train Acc: 98.69%, Valid Loss: 0.0584, Valid Acc: 98.28%, Test Loss: 0.0526, Test Acc: 98.45%, Train Time: 16.82s
Epoch 7/25, Train Loss: 0.0316, Train Acc: 98.99%, Valid Loss: 0.0593, Valid Acc: 98.43%, Test Loss: 0.0514, Test Acc: 98.49%, Train Time: 17.20s
Epoch 8/25, Train Loss: 0.0272, Train Acc: 99.11%, Valid Loss: 0.0607, Valid Acc: 98.42%, Test Loss: 0.0500, Test Acc: 98.46%, Train Time: 17.41s
Epoch 9/25, Train Loss: 0.0230, Train Acc: 99.22%, Valid Loss: 0.0585, Valid Acc: 98.60%, Test Loss: 0.0610, Test Acc: 98.43%, Train Time: 17.30s
Epoch 10/25, Train Loss: 0.0199, Train Acc: 99.32%, Valid Loss: 0.0690, Valid Acc: 98.19%, Test Loss: 0.0696, Test Acc: 98.27%, Train Time: 16.89s
Model saved at epoch 11 with validation loss 0.0530.
Epoch 11/25, Train Loss: 0.0074, Train Acc: 99.77%, Valid Loss: 0.0530, Valid Acc: 98.73%, Test Loss: 0.0510, Test Acc: 98.67%, Train Time: 16.92s
Epoch 12/25, Train Loss: 0.0042, Train Acc: 99.90%, Valid Loss: 0.0547, Valid Acc: 98.65%, Test Loss: 0.0512, Test Acc: 98.68%, Train Time: 16.69s
Epoch 13/25, Train Loss: 0.0032, Train Acc: 99.94%, Valid Loss: 0.0544, Valid Acc: 98.80%, Test Loss: 0.0532, Test Acc: 98.72%, Train Time: 16.34s
Epoch 14/25, Train Loss: 0.0024, Train Acc: 99.96%, Valid Loss: 0.0573, Valid Acc: 98.74%, Test Loss: 0.0585, Test Acc: 98.67%, Train Time: 19.27s
Epoch 15/25, Train Loss: 0.0019, Train Acc: 99.97%, Valid Loss: 0.0613, Valid Acc: 98.76%, Test Loss: 0.0601, Test Acc: 98.71%, Train Time: 19.35s
Epoch 16/25, Train Loss: 0.0013, Train Acc: 99.98%, Valid Loss: 0.0602, Valid Acc: 98.78%, Test Loss: 0.0597, Test Acc: 98.69%, Train Time: 19.68s
Epoch 17/25, Train Loss: 0.0012, Train Acc: 99.99%, Valid Loss: 0.0604, Valid Acc: 98.81%, Test Loss: 0.0600, Test Acc: 98.70%, Train Time: 18.15s
Epoch 18/25, Train Loss: 0.0011, Train Acc: 99.99%, Valid Loss: 0.0612, Valid Acc: 98.80%, Test Loss: 0.0607, Test Acc: 98.67%, Train Time: 17.43s
Early stopping at epoch 18. No improvement in validation loss for 7 consecutive epochs.
Loaded the best model state based on validation loss.

        ############### Training completed in 313.38s. ###############
        Average time per epoch: 17.41s.
        Trained for 18/25 epochs.
        ##############################################################
        

############################## Training completed ##############################
========================================================================================================

!---------------------------- Quantised model saved to: experiments\exp017\quantised_model.pth ----------------------------!
scale=0.007870171219110489
zero_point=0
!-------------------------------------------------------------------------------------------------------------------------!

Model quantised:
CNNLeNet(
  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (conv1): QuantizedConv2d(2, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.10679341107606888, zero_point=76, bias=False)
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.261362224817276, zero_point=79, bias=False)
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): QuantizedConv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), scale=0.3414236903190613, zero_point=79, bias=False)
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): QuantizedLinear(in_features=120, out_features=84, scale=0.3348349928855896, zero_point=66, qscheme=torch.per_channel_affine)
  (relu4): ReLU()
  (fc2): QuantizedLinear(in_features=84, out_features=10, scale=0.7119020223617554, zero_point=78, qscheme=torch.per_channel_affine)
)
========================================================================================================

######################################### Classification report #########################################
              precision    recall  f1-score   support

           0     0.9838    0.9939    0.9888       980
           1     0.9912    0.9956    0.9934      1135
           2     0.9827    0.9913    0.9870      1032
           3     0.9823    0.9881    0.9852      1010
           4     0.9869    0.9939    0.9904       982
           5     0.9809    0.9798    0.9804       892
           6     0.9894    0.9770    0.9832       958
           7     0.9912    0.9874    0.9893      1028
           8     0.9805    0.9795    0.9800       974
           9     0.9909    0.9722    0.9815      1009

    accuracy                         0.9861     10000
   macro avg     0.9860    0.9859    0.9859     10000
weighted avg     0.9861    0.9861    0.9861     10000


##########################################################################################################

############################################# Accuracy score #############################################
0.9861

##########################################################################################################

##################### [Inference time] - Testing model for 5 iterations #####################

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 10000, Accuracy: 98.61%
Inference time for iteration 1: 0 min 11.17 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 10000, Accuracy: 98.61%
Inference time for iteration 2: 0 min 9.86 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 10000, Accuracy: 98.61%
Inference time for iteration 3: 0 min 9.11 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 10000, Accuracy: 98.61%
Inference time for iteration 4: 0 min 9.11 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 10000, Accuracy: 98.61%
Inference time for iteration 5: 0 min 8.73 sec

Average Inference time over 5 iterations: 0 min 9.60 sec

##################### [Inference time] - Testing completed #####################
