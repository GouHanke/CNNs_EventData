========================================================================================================
Experiment: exp022
Checkpoint path: experiments/exp022/checkpoint.pth

######################### Model architecture #########################
MobileNet(
  (conv1): Sequential(
    (0): Conv2d(2, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
  )
  (conv2): DepthwiseSeparableConv(
    (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
    (pointwise): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv3): DepthwiseSeparableConv(
    (depthwise): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
    (pointwise): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv4): DepthwiseSeparableConv(
    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
    (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv5): DepthwiseSeparableConv(
    (depthwise): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)
    (pointwise): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv6): DepthwiseSeparableConv(
    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)
    (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv7): DepthwiseSeparableConv(
    (depthwise): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)
    (pointwise): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv8): Sequential(
    (0): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (1): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (2): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (3): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (4): DepthwiseSeparableConv(
      (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)
      (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
  )
  (conv9): DepthwiseSeparableConv(
    (depthwise): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)
    (pointwise): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (conv10): DepthwiseSeparableConv(
    (depthwise): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)
    (pointwise): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc): Linear(in_features=1024, out_features=1, bias=True)
)
Total number of paramters in the model: 3185889
Quantised model: False

################### Model successfully initialised ###################

################## Setting up training components ##################
Number of classes: 2
Model quantised: False
Device: (GPU)
name, memory.total [MiB], memory.free [MiB]
NVIDIA GeForce RTX 3060, 12288 MiB, 10209 MiB
Number of epochs: 40
Criteria: BCEWithLogitsLoss()
Optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.001
    maximize: False
    weight_decay: 0
)
Scheduler: <torch.optim.lr_scheduler.ReduceLROnPlateau object at 0x0000021CA84F9780>
Patience: 7

################## Training components set up successfully ##################

############################## Data loading ##############################
Train set path: data/ncars/max_32x32_DATASETS/plain/train_n_cars_dataset_maxpooling_1framepereventset_plain.pth
Valid set path: data/ncars/max_32x32_DATASETS/plain/valid_n_cars_dataset_maxpooling_1framepereventset_plain.pth
Test set path: data/ncars/max_32x32_DATASETS/plain/test_n_cars_dataset_maxpooling_1framepereventset_plain.pth
Total number of samples in train_loader: 11566
Total number of samples in valid_loader: 3856
Total number of samples in test_loader: 8607

######################### Data loaded successfully #########################

################################## checkpoint info ##################################
No checkpoint found at experiments/exp022/checkpoint.pth. Starting training from scratch.

#####################################################################################

############################## Training started ##############################
Model saved at epoch 1 with validation loss 0.4559.
Epoch 1/40, Train Loss: 0.5552, Train Acc: 69.37%, Valid Loss: 0.4559, Valid Acc: 80.65%, Test Loss: 0.6366, Test Acc: 70.64%, Train Time: 2.62s
Model saved at epoch 2 with validation loss 0.3882.
Epoch 2/40, Train Loss: 0.3891, Train Acc: 82.79%, Valid Loss: 0.3882, Valid Acc: 82.96%, Test Loss: 0.5278, Test Acc: 73.37%, Train Time: 2.28s
Epoch 3/40, Train Loss: 0.3642, Train Acc: 84.86%, Valid Loss: 0.3886, Valid Acc: 82.18%, Test Loss: 0.5297, Test Acc: 73.70%, Train Time: 2.25s
Epoch 4/40, Train Loss: 0.3285, Train Acc: 85.91%, Valid Loss: 0.4002, Valid Acc: 82.31%, Test Loss: 0.5166, Test Acc: 74.01%, Train Time: 2.24s
Model saved at epoch 5 with validation loss 0.3875.
Epoch 5/40, Train Loss: 0.3105, Train Acc: 86.82%, Valid Loss: 0.3875, Valid Acc: 82.57%, Test Loss: 0.5284, Test Acc: 73.77%, Train Time: 2.23s
Model saved at epoch 6 with validation loss 0.3858.
Epoch 6/40, Train Loss: 0.2909, Train Acc: 87.73%, Valid Loss: 0.3858, Valid Acc: 83.53%, Test Loss: 0.5350, Test Acc: 76.15%, Train Time: 2.28s
Model saved at epoch 7 with validation loss 0.3728.
Epoch 7/40, Train Loss: 0.2785, Train Acc: 88.66%, Valid Loss: 0.3728, Valid Acc: 83.22%, Test Loss: 0.5213, Test Acc: 74.90%, Train Time: 2.27s
Epoch 8/40, Train Loss: 0.2700, Train Acc: 89.11%, Valid Loss: 0.4150, Valid Acc: 82.31%, Test Loss: 0.5997, Test Acc: 74.56%, Train Time: 2.26s
Epoch 9/40, Train Loss: 0.2536, Train Acc: 89.53%, Valid Loss: 0.4276, Valid Acc: 82.81%, Test Loss: 0.6016, Test Acc: 75.06%, Train Time: 2.24s
Epoch 10/40, Train Loss: 0.2421, Train Acc: 90.15%, Valid Loss: 0.4177, Valid Acc: 81.38%, Test Loss: 0.6219, Test Acc: 73.87%, Train Time: 2.28s
Epoch 11/40, Train Loss: 0.2355, Train Acc: 90.54%, Valid Loss: 0.4586, Valid Acc: 82.83%, Test Loss: 0.6773, Test Acc: 76.17%, Train Time: 2.28s
Epoch 12/40, Train Loss: 0.1764, Train Acc: 93.07%, Valid Loss: 0.4800, Valid Acc: 81.92%, Test Loss: 0.7286, Test Acc: 74.66%, Train Time: 2.26s
Epoch 13/40, Train Loss: 0.1634, Train Acc: 93.63%, Valid Loss: 0.5019, Valid Acc: 81.82%, Test Loss: 0.7597, Test Acc: 74.64%, Train Time: 2.24s
Epoch 14/40, Train Loss: 0.1537, Train Acc: 93.99%, Valid Loss: 0.5211, Valid Acc: 81.72%, Test Loss: 0.7884, Test Acc: 74.47%, Train Time: 2.23s
Early stopping at epoch 14. No improvement in validation loss for 7 consecutive epochs.
Loaded the best model state based on validation loss.

        ############### Training completed in 31.94s. ###############
        Average time per epoch: 2.28s.
        Trained for 14/40 epochs.
        ##############################################################
        

############################## Training completed ##############################
============================== Model saved to: experiments\exp022\model.pth ==============================

######################################### Classification report #########################################
              precision    recall  f1-score   support

         0.0     0.7261    0.7680    0.7465      4211
         1.0     0.7647    0.7225    0.7430      4396

    accuracy                         0.7447      8607
   macro avg     0.7454    0.7452    0.7447      8607
weighted avg     0.7458    0.7447    0.7447      8607


##########################################################################################################

############################################# Accuracy score #############################################
0.7447426513303126

##########################################################################################################
Model is on device: cuda

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 8607, Accuracy: 74.47%
Inference time for iteration 1: 0 min 12.44 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 8607, Accuracy: 74.47%
Inference time for iteration 2: 0 min 11.98 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 8607, Accuracy: 74.47%
Inference time for iteration 3: 0 min 11.96 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 8607, Accuracy: 74.47%
Inference time for iteration 4: 0 min 12.46 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 8607, Accuracy: 74.47%
Inference time for iteration 5: 0 min 11.53 sec

Average Inference time over 5 iterations: 0 min 12.07 sec

Average Inference time per sample: 1.40 ms

##################### [Inference time] - Testing completed #####################
