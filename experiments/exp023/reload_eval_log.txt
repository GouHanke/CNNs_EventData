
-------------------- Extract model info from the train_log.txt -------------------
Class of the model: CNNLeNet
Quantised model: True
Number of classes: 2
(num_classes = 1)
Test set path: data/ncars/ave_32x32_DATASETS/plain/test_n_cars_dataset_poolingave_1framepereventset_plain.pth
Scale: 0.228251114487648
Zero point: 4

-------------------- Model info extracted successfully -------------------

------------------- Model initialisation and loading -------------------
Model was quantised, model structure: 
CNNLeNet_q(
  (quant): Quantize(scale=tensor([0.2283]), zero_point=tensor([4]), dtype=torch.quint8)
  (dequant): DeQuantize()
  (conv1): QuantizedConv2d(2, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.4420357942581177, zero_point=70, bias=False)
  (relu1): ReLU()
  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.44496163725852966, zero_point=90, bias=False)
  (relu2): ReLU()
  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)
  (conv3): QuantizedConv2d(16, 120, kernel_size=(5, 5), stride=(1, 1), scale=0.4862687885761261, zero_point=82, bias=False)
  (relu3): ReLU()
  (avgpool): AdaptiveAvgPool2d(output_size=1)
  (fc1): QuantizedLinear(in_features=120, out_features=84, scale=0.31012269854545593, zero_point=53, qscheme=torch.per_channel_affine)
  (relu4): ReLU()
  (fc2): QuantizedLinear(in_features=84, out_features=1, scale=1.5065348148345947, zero_point=67, qscheme=torch.per_channel_affine)
)
Load model from: experiments/exp023/quantised_model.pth

------------------- Model successfully initialised ------------------- 

------------------------------- Test Data loading -------------------------------
Test set path: data/ncars/ave_32x32_DATASETS/plain/test_n_cars_dataset_poolingave_1framepereventset_plain.pth
Total number of samples in test_loader: 8607

---------------------------- Test Data loaded successfully ----------------------------

######################################### Classification report #########################################
              precision    recall  f1-score   support

         0.0     0.7179    0.7592    0.7380      4211
         1.0     0.7559    0.7143    0.7345      4396

    accuracy                         0.7363      8607
   macro avg     0.7369    0.7367    0.7362      8607
weighted avg     0.7373    0.7363    0.7362      8607


##########################################################################################################

############################################# Accuracy score #############################################
0.7362611827582201

##########################################################################################################

##################### [Inference time] - Testing model for 5 iterations #####################

### Testing - Iteration 1/5 ###


Iteration 1 completed: Total examples: 8607, Accuracy: 73.63%
Inference time for iteration 1: 0 min 7.76 sec

### Testing - Iteration 2/5 ###


Iteration 2 completed: Total examples: 8607, Accuracy: 73.63%
Inference time for iteration 2: 0 min 7.70 sec

### Testing - Iteration 3/5 ###


Iteration 3 completed: Total examples: 8607, Accuracy: 73.63%
Inference time for iteration 3: 0 min 7.69 sec

### Testing - Iteration 4/5 ###


Iteration 4 completed: Total examples: 8607, Accuracy: 73.63%
Inference time for iteration 4: 0 min 8.55 sec

### Testing - Iteration 5/5 ###


Iteration 5 completed: Total examples: 8607, Accuracy: 73.63%
Inference time for iteration 5: 0 min 8.75 sec

Average Inference time over 5 iterations: 0 min 8.09 sec

Average Inference time per sample: 0.94 ms

##################### [Inference time] - Testing completed #####################
